{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_files(json_path, folder):\n",
    "    file_name = os.path.splitext(os.path.basename(json_path))[0]\n",
    "    # Make it a plain strings with only letters and numbers\n",
    "    file_name = ''.join(e for e in file_name if e.isalnum())\n",
    "    file = json.loads(open(json_path).read())\n",
    "    sub_folder = f'{folder}/{file_name}'\n",
    "    os.makedirs(sub_folder, exist_ok=True)\n",
    "\n",
    "    for key in file:\n",
    "        # Create suffix with the matched keyword and the last part of the key\n",
    "        suffix = f\"{next((word for word in ['book', 'work', 'author', 'series'] if word in key), key)}_{key.split('.')[-1]}\"\n",
    "        with open(f'{sub_folder}/{file_name}_{suffix}.json', 'w') as f:\n",
    "            json.dump(file[key], f, indent=4)\n",
    "            print(f'Created {file_name}_{suffix}.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'book_details'\n",
    "# For each json in the folder cann save_json_files\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith('.json'):\n",
    "        save_json_files(f'{folder}/{file}', folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book details: {'legacyId': 28949218, 'title': 'The Flame Bearer', 'primaryContributorEdge_role': 'Author', 'primaryContributorEdge_ref': 'Contributor:kca://author/amzn1.gr.author.v1.wlwi3fZJNsgRxAOMSIOIbw', 'secondaryContributorEdges': [], 'bookSeries': ['Series:kca://series/amzn1.gr.series.v1._wedZzHR7zE0Lx56fNmudA'], 'bookGenres': ['Historical Fiction', 'Fiction', 'Historical', 'Audiobook', 'Fantasy', 'Medieval', 'Adventure', 'War', 'British Literature', 'Novels'], 'numPages': 284, 'publicationTime': 1475737200000, 'publisher': 'HARPER COLLINS', 'language': 'English', 'work_ref': 'Work:kca://work/amzn1.gr.work.v1.Qs-mhpnPXcpKcbVxST-rSA'}\n"
     ]
    }
   ],
   "source": [
    "def extract_relevant_fields(json_path):\n",
    "    file = json.loads(open(json_path).read())\n",
    "    # Get the keys\n",
    "    keys = file.keys()\n",
    "    # from the key that contains 'book' get the values\n",
    "    book = file[next((key for key in keys if 'Book' in key), None)]\n",
    "    # from the key that contains 'work' get the values\n",
    "    work = file[next((key for key in keys if 'Work' in key), None)]\n",
    "    # from each key that contains 'author' get the values\n",
    "    authors = [file[key] for key in keys if 'Contributor' in key]\n",
    "    # from each key that contains 'serie' get the values\n",
    "    series = [file[key] for key in keys if 'Series' in key]\n",
    "    return book, work, authors, series\n",
    "\n",
    "# Extract book details\n",
    "def extract_book_details(book: dict):\n",
    "    details = {}\n",
    "    details['legacyId'] = book.get('legacyId')\n",
    "    details['title'] = book.get('title')\n",
    "    details['primaryContributorEdge_role'] = book.get('primaryContributorEdge').get('role')\n",
    "    details['primaryContributorEdge_ref'] = book.get('primaryContributorEdge').get('node').get('__ref')\n",
    "    # Extract secondaryContributorEdges and append them as a list of dictionaries in details\n",
    "    details['secondaryContributorEdges'] = [\n",
    "        {'role': contributor.get('role'), 'ref': contributor.get('node', {}).get('__ref')}\n",
    "        for contributor in book.get('secondaryContributorEdges', [])\n",
    "    ]\n",
    "    details['bookSeries'] = [series.get('series', {}).get('__ref') for series in book.get('bookSeries', [])]\n",
    "    details['bookGenres'] = [genre.get('genre', {}).get('name') for genre in book.get('bookGenres', [])]\n",
    "    details['numPages'] = book.get('details').get('numPages')\n",
    "    details['publicationTime'] = book.get('details').get('publicationTime')\n",
    "    details['publisher'] = book.get('details').get('publisher')\n",
    "    details['language'] = book.get('details').get('language').get('name')\n",
    "    details['work_ref'] = book.get('work').get('__ref')\n",
    "    return details\n",
    "\n",
    "# Extract work details\n",
    "def extract_work_details(work: dict):\n",
    "    details = {}\n",
    "    details['legacyId'] = work.get('legacyId')\n",
    "    details['originalTitle'] = work.get('details').get('originalTitle')\n",
    "    details['characters'] = [character.get('name') for character in work.get('details').get('characters', [])]\n",
    "    details['editions_url'] = work.get('editions').get('webUrl')\n",
    "    return details\n",
    "\n",
    "# Extract author details\n",
    "def extract_author_details(authors: list):\n",
    "    details = []\n",
    "    for author in authors:\n",
    "        author_details = {}\n",
    "        author_details['legacyId'] = author.get('legacyId')\n",
    "        author_details['name'] = author.get('name')\n",
    "        author_details['description'] = author.get('description')\n",
    "        author_details['webUrl'] = author.get('webUrl')\n",
    "        details.append(author_details)\n",
    "    return details\n",
    "\n",
    "# Extract series details\n",
    "def extract_series_details(series: list):\n",
    "    details = []\n",
    "    for serie in series:\n",
    "        serie_details = {}\n",
    "        serie_details['title'] = serie.get('title')\n",
    "        details.append(serie_details)\n",
    "    return details\n",
    "\n",
    "# Extract all the details\n",
    "def extract_all_details(json_path):\n",
    "    book, work, authors, series = extract_relevant_fields(json_path)\n",
    "    return extract_book_details(book), extract_work_details(work), extract_author_details(authors), extract_series_details(series)\n",
    "\n",
    "# Extract all the details from the json\n",
    "book_details, work_details, author_details, series_details = extract_all_details('book_details/The_Flame_Bearer_(The_Saxon_Stories,_#10).json')\n",
    "\n",
    "print('Book details:', book_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged details: {'legacyId': 49172708, 'title': 'The Flame Bearer', 'primaryContributorEdge_role': 'Author', 'primaryContributorEdge_ref': 'Contributor:kca://author/amzn1.gr.author.v1.wlwi3fZJNsgRxAOMSIOIbw', 'secondaryContributorEdges': [], 'bookSeries': ['Series:kca://series/amzn1.gr.series.v1._wedZzHR7zE0Lx56fNmudA'], 'bookGenres': ['Historical Fiction', 'Fiction', 'Historical', 'Audiobook', 'Fantasy', 'Medieval', 'Adventure', 'War', 'British Literature', 'Novels'], 'numPages': 284, 'publicationTime': 1475737200000, 'publisher': 'HARPER COLLINS', 'language': 'English', 'work_ref': 'Work:kca://work/amzn1.gr.work.v1.Qs-mhpnPXcpKcbVxST-rSA', 'originalTitle': 'The Flame Bearer', 'characters': ['Edward the Elder', 'Uhtred of Bebbanburg', 'Constantine II, King of Alba', 'Aethelflaed'], 'editions_url': 'https://www.goodreads.com/work/editions/49172708', 'series': [{'title': 'The Last Kingdom'}]}\n"
     ]
    }
   ],
   "source": [
    "# Merge the details in a single dictionary (except authors_details)\n",
    "merged_details = {**book_details, **work_details, 'series': series_details}\n",
    "print('Merged details:', merged_details)\n",
    "\n",
    "import csv\n",
    "# Save the merged details in a csv file\n",
    "def save_details_to_csv(details, csv_file):\n",
    "    with open(csv_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=details.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(details)\n",
    "\n",
    "save_details_to_csv(merged_details, 'merged_details.csv')\n",
    "\n",
    "# Author details is a list of dicts with keys 'legacyId', 'name', 'description', convert each element in a row\n",
    "def save_author_details_to_csv(author_details, csv_file):\n",
    "    with open(csv_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=author_details[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(author_details)\n",
    "\n",
    "save_author_details_to_csv(author_details, 'author_details.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
